{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.plots import *\n",
    "from torchtext.data import Field\n",
    "from fastai.lm_rnn import seq2seq_reg\n",
    "from quicknlp import SpacyTokenizer, print_batch, S2SModelData\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"dataset/translation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fra.txt \u001b[34mtrain\u001b[m\u001b[m   \u001b[34mvalid\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!cd $DATAPATH; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't find model 'fr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d75d91db9e37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m fields = [\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINIT_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEOS_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSpacyTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"french\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINIT_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEOS_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSpacyTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m ]\n",
      "\u001b[0;32m~/workspace/personal/quick-nlp/src/quicknlp/data/spacy_tokenizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_special_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mORTH\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_special_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<bos>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mORTH\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'<bos>'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-venv/lib/python3.6/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;34m\"to load. For example:\\nnlp = spacy.load('{}')\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             'error')\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-venv/lib/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't find model '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't find model 'fr'"
     ]
    }
   ],
   "source": [
    "INIT_TOKEN = \"<sos>\"\n",
    "EOS_TOKEN = \"<eos>\"\n",
    "fields = [\n",
    "    (\"english\", Field(init_token=INIT_TOKEN, eos_token=EOS_TOKEN, tokenize=SpacyTokenizer('en'), lower=True)),\n",
    "    (\"french\", Field(init_token=INIT_TOKEN, eos_token=EOS_TOKEN, tokenize=SpacyTokenizer('fr'), lower=True))\n",
    "\n",
    "]\n",
    "batch_size = 64\n",
    "data = S2SModelData.from_text_files(path=DATAPATH, fields=fields,\n",
    "                                    train=\"train\",\n",
    "                                    validation=\"validation\",\n",
    "                                    source_names=[\"english\", \"french\"],\n",
    "                                    target_names=[\"french\"],\n",
    "                                    bs= batch_size\n",
    "                                   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tr batches: 4, num tr samples: 201\n",
      "num val batches: 4,num val samples: 201\n"
     ]
    }
   ],
   "source": [
    "print(f'num tr batches: {len(data.trn_dl)}, num tr samples: {len(data.trn_ds)}')\n",
    "print(f'num val batches: {len(data.val_dl)},num val samples: {len(data.val_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 300\n",
    "nh = 1024\n",
    "nl = 3\n",
    "tnh = 512\n",
    "learner = data.get_model(emb_sz=emb_size,\n",
    "                         nhid=nh,\n",
    "                         nlayers=nl,\n",
    "                         bidir=True,\n",
    "                         max_iterations=30,\n",
    "                         att_nhid=tnh,\n",
    "                         attention=True\n",
    "                         )\n",
    "reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "clip = 0.3\n",
    "learner.reg_fn = reg_fn\n",
    "learner.clip = clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqAttention(\n",
      "  (encoder): RNNEncoder(\n",
      "    (encoder): Embedding(102, 300, padding_idx=1)\n",
      "    (encoder_with_dropout): EmbeddingDropout(\n",
      "      (embed): Embedding(102, 300, padding_idx=1)\n",
      "    )\n",
      "    (rnns): ModuleList(\n",
      "      (0): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(300, 512, dropout=0.3, bidirectional=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(1024, 512, dropout=0.3, bidirectional=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(1024, 150, dropout=0.3, bidirectional=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dropouti): LockedDropout(\n",
      "    )\n",
      "    (dropouths): ModuleList(\n",
      "      (0): LockedDropout(\n",
      "      )\n",
      "      (1): LockedDropout(\n",
      "      )\n",
      "      (2): LockedDropout(\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): RNNAttentionDecoder(\n",
      "    (encoder): Embedding(209, 300, padding_idx=1)\n",
      "    (encoder_with_dropout): EmbeddingDropout(\n",
      "      (embed): Embedding(209, 300, padding_idx=1)\n",
      "    )\n",
      "    (rnns): ModuleList(\n",
      "      (0): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(600, 1024, dropout=0.3)\n",
      "        )\n",
      "      )\n",
      "      (1): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(1024, 1024, dropout=0.3)\n",
      "        )\n",
      "      )\n",
      "      (2): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(1024, 300, dropout=0.3)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dropouti): LockedDropout(\n",
      "    )\n",
      "    (dropouths): ModuleList(\n",
      "      (0): LockedDropout(\n",
      "      )\n",
      "      (1): LockedDropout(\n",
      "      )\n",
      "      (2): LockedDropout(\n",
      "      )\n",
      "    )\n",
      "    (projection_layer): AttentionProjection(\n",
      "      (attention): MLPAttention(\n",
      "        (linear1): Linear(in_features=600, out_features=512, bias=False)\n",
      "        (linear2): Linear(in_features=512, out_features=1, bias=False)\n",
      "      )\n",
      "      (projection1): Projection(\n",
      "        (linear): Linear(in_features=600, out_features=300, bias=False)\n",
      "        (dropout): LockedDropout(\n",
      "        )\n",
      "      )\n",
      "      (projection2): Projection(\n",
      "        (linear): Linear(in_features=300, out_features=209, bias=False)\n",
      "        (dropout): LockedDropout(\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0 sample : 0\n",
      "input: <sos> join us . <eos> <pad>\n",
      "target: joignez - vous Ã  nous . <eos> <pad>\n",
      "prediction: ['<sos> gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles']\n",
      "\n",
      "\n",
      "batch: 0 sample : 1\n",
      "input: <sos> join us . <eos> <pad>\n",
      "target: joignez - vous . <eos> <pad> <pad> <pad>\n",
      "prediction: ['<sos> gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles']\n",
      "\n",
      "\n",
      "batch: 0 sample : 2\n",
      "input: <sos> jump . <eos> <pad> <pad>\n",
      "target: saute . <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "prediction: ['<sos> gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles']\n",
      "\n",
      "\n",
      "batch: 0 sample : 3\n",
      "input: <sos> keep it . <eos> <pad>\n",
      "target: garde - le ! <eos> <pad> <pad> <pad>\n",
      "prediction: ['<sos> gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles']\n",
      "\n",
      "\n",
      "batch: 0 sample : 4\n",
      "input: <sos> keep it . <eos> <pad>\n",
      "target: gardez - le ! <eos> <pad> <pad> <pad>\n",
      "prediction: ['<sos> gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles']\n",
      "\n",
      "\n",
      "batch: 0 sample : 5\n",
      "input: <sos> kiss me . <eos> <pad>\n",
      "target: embrassez - moi . <eos> <pad> <pad> <pad>\n",
      "prediction: ['<sos> gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles gentilles']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_batch(lr=learner,dt=data, input_field=\"english\", output_field=\"french\",num_sentences=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
